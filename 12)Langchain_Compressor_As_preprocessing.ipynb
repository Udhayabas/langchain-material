{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45bdd7fa-c214-42ad-b672-36d3efacf0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramisha Aravind\\AppData\\Local\\Temp\\ipykernel_29932\\1570214816.py:16: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
      "C:\\Users\\Ramisha Aravind\\AppData\\Local\\Temp\\ipykernel_29932\\1570214816.py:17: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Compressed Summary:\n",
      "- LangChain is a framework for building applications with LLMs.LangChain was created by Harrison Chase.LangChain supports RAG, agents, memory, tools, and more.Itâ€™s commonly used in chatbots, document Q&A, and AI workflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramisha Aravind\\AppData\\Local\\Temp\\ipykernel_29932\\1570214816.py:40: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  qa_chain = LLMChain(llm=llm, prompt=qa_prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¡ Answer to your question:\n",
      "The main idea of the document is to introduce LangChain as a framework created by Harrison Chase for building applications with LLMs. It highlights the features and uses of LangChain, such as supporting RAG, agents, memory, tools, and its common applications in chatbots, document Q&A, and AI workflow.\n"
     ]
    }
   ],
   "source": [
    "# 1. Imports\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.schema.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "# 2. Setup LLM and Embeddings\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# 3. Load your document\n",
    "with open(\"sample.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "# 4. Split it into chunks\n",
    "splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=300, chunk_overlap=50)\n",
    "chunks = splitter.split_text(raw_text)\n",
    "documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "# 5. Compress the documents using LLMChainExtractor\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compressed_docs = compressor.compress_documents(documents, query=\"Summarize the key points\")\n",
    "\n",
    "print(\"âœ… Compressed Summary:\")\n",
    "for doc in compressed_docs:\n",
    "    print(\"-\", doc.page_content)\n",
    "\n",
    "# 6. Now ask a question about the compressed content using a custom LLMChain\n",
    "qa_prompt = PromptTemplate.from_template(\n",
    "    \"Given the context below, answer the question:\\n\\nContext:\\n{context}\\n\\nQuestion: {question}\"\n",
    ")\n",
    "qa_chain = LLMChain(llm=llm, prompt=qa_prompt)\n",
    "\n",
    "response = qa_chain.invoke({\n",
    "    \"context\": \"\\n\".join([doc.page_content for doc in compressed_docs]),\n",
    "    \"question\": \"What is the main idea of the document?\"\n",
    "})\n",
    "\n",
    "print(\"\\nðŸ’¡ Answer to your question:\")\n",
    "print(response[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f6afc8-609a-406f-a50c-9189acbc5db5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
